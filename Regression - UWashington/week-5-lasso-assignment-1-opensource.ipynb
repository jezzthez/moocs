{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import log, sqrt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('data/kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = \n",
    "['bedrooms', 'bedrooms_square', 'bathrooms', 'sqft_living', \n",
    " 'sqft_living_sqrt', 'sqft_lot', 'sqft_lot_sqrt', 'floors', \n",
    " 'floors_square', 'waterfront', 'view', 'condition', \n",
    " 'grade', 'sqft_above', 'sqft_basement', 'yr_built', \n",
    " 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True) # set parameters\n",
    "model_all.fit(sales[all_features], sales['price']) # learn weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0.        ,      0.        ,      0.        ,    134.43931396,\n",
       "            0.        ,      0.        ,      0.        ,      0.        ,\n",
       "            0.        ,      0.        ,  24750.00458561,      0.        ,\n",
       "        61749.10309071,      0.        ,      0.        ,     -0.        ,\n",
       "            0.        ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = pd.read_csv('data/wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('data/wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('data/wk3_kc_house_valid_data.csv', dtype=dtype_dict)\n",
    "\n",
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RSS 398213327300135.062500 is for 10.00\n",
      "the RSS 399041900253346.937500 is for 31.62\n",
      "the RSS 429791604072559.500000 is for 100.00\n",
      "the RSS 463739831045121.375000 is for 316.23\n",
      "the RSS 645898733633807.000000 is for 1000.00\n",
      "the RSS 1222506859427163.000000 is for 3162.28\n",
      "the RSS 1222506859427163.000000 is for 10000.00\n",
      "the RSS 1222506859427163.000000 is for 31622.78\n",
      "the RSS 1222506859427163.000000 is for 100000.00\n",
      "the RSS 1222506859427163.000000 is for 316227.77\n",
      "the RSS 1222506859427163.000000 is for 1000000.00\n",
      "the RSS 1222506859427163.000000 is for 3162277.66\n",
      "the RSS 1222506859427163.000000 is for 10000000.00\n"
     ]
    }
   ],
   "source": [
    "l1_list = np.logspace(1, 7, num=13)\n",
    "\n",
    "for l1_penalty in l1_list:\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    predictions = model.predict(validation[all_features])\n",
    "    RSS = ((predictions - validation['price']) ** 2).sum()\n",
    "    print ('the RSS %f is for %.2f' % (RSS, l1_penalty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RSS is 9.84674025527e+13\n"
     ]
    }
   ],
   "source": [
    "model10 = linear_model.Lasso(alpha=10, normalize=True)\n",
    "model10.fit(training[all_features], training['price'])\n",
    "predictions = model10.predict(testing[all_features])\n",
    "RSS = ((predictions - testing['price']) ** 2).sum()\n",
    "print 'the RSS is ' + str(RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(model10.coef_) + np.count_nonzero(model10.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 102])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(100,102) + np.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 125.89254118,  130.5537869 ,  135.387618  ,  140.40042455,\n",
       "        145.59883323,  150.98971606,  156.58019951,  162.37767392,\n",
       "        168.38980324,  174.6245352 ,  181.0901118 ,  187.79508019,\n",
       "        194.74830399,  201.95897502,  209.4366254 ,  217.1911402 ,\n",
       "        225.2327705 ,  233.57214691,  242.22029366,  251.18864315])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(2.1, 2.4, num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values_min = np.arange(150,158)\n",
    "l1_penalty_values_max = np.arange(201,210)\n",
    "nonzeros_min = [0 for i in range(len(l1_penalty_values))]\n",
    "nonzeros_max = [0 for i in range(len(l1_penalty_values))]\n",
    "\n",
    "for index, l1_penalty in enumerate(l1_penalty_values_min):\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    non_zeros = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "    nonzeros_min[index] = non_zeros\n",
    "    \n",
    "for index, l1_penalty in enumerate(l1_penalty_values_max):\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    non_zeros = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "    nonzeros_max[index] = non_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(150, 8), (151, 8), (152, 8), (153, 8), (154, 7), (155, 7), (156, 7), (157, 7)]\n"
     ]
    }
   ],
   "source": [
    "print zip(l1_penalty_values_min, nonzeros_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(201, 7), (202, 7), (203, 7), (204, 7), (205, 7), (206, 7), (207, 6), (208, 6), (209, 6)]\n"
     ]
    }
   ],
   "source": [
    "print zip(l1_penalty_values_max, nonzeros_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_min = 153\n",
    "l1_penalty_max = 207"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty:154.0 RSS:4.39830405618e+14 params:7\n",
      "penalty:156.736842105 RSS:4.40101738965e+14 params:7\n",
      "penalty:159.473684211 RSS:4.40379199789e+14 params:7\n",
      "penalty:162.210526316 RSS:4.40664156517e+14 params:7\n",
      "penalty:164.947368421 RSS:4.40956562622e+14 params:7\n",
      "penalty:167.684210526 RSS:4.4125631679e+14 params:7\n",
      "penalty:170.421052632 RSS:4.41563422343e+14 params:7\n",
      "penalty:173.157894737 RSS:4.41877890495e+14 params:7\n",
      "penalty:175.894736842 RSS:4.42199721248e+14 params:7\n",
      "penalty:178.631578947 RSS:4.42528901401e+14 params:7\n",
      "penalty:181.368421053 RSS:4.42865477648e+14 params:7\n",
      "penalty:184.105263158 RSS:4.43209423841e+14 params:7\n",
      "penalty:186.842105263 RSS:4.43560733529e+14 params:7\n",
      "penalty:189.578947368 RSS:4.43921675722e+14 params:7\n",
      "penalty:192.315789474 RSS:4.44287618625e+14 params:7\n",
      "penalty:195.052631579 RSS:4.44660886271e+14 params:7\n",
      "penalty:197.789473684 RSS:4.45041483551e+14 params:7\n",
      "penalty:200.526315789 RSS:4.45429302184e+14 params:7\n",
      "penalty:203.263157895 RSS:4.45824308884e+14 params:7\n",
      "penalty:206.0 RSS:4.46228747759e+14 params:7\n"
     ]
    }
   ],
   "source": [
    "l1_penalty_values = np.linspace(154, 206,20)\n",
    "\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    predictions = model.predict(validation[all_features])\n",
    "    RSS = ((predictions - validation['price']) ** 2).sum()\n",
    "    non_zeros = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "    print 'penalty:' + str(l1_penalty) + ' RSS:' + str(RSS) + ' params:' + str(non_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.00000000e+00  -0.00000000e+00   1.10522651e+04   1.63241881e+02\n",
      "   0.00000000e+00  -0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.08131958e+05   4.19961061e+04   0.00000000e+00\n",
      "   1.16473748e+05   0.00000000e+00   0.00000000e+00  -2.62757421e+03\n",
      "   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "model154 = linear_model.Lasso(alpha=154, normalize=True)\n",
    "model154.fit(training[all_features], training['price'])\n",
    "print model154.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = \n",
    "['bedrooms', 'bedrooms_square', 'bathrooms', 'sqft_living', \n",
    " 'sqft_living_sqrt', 'sqft_lot', 'sqft_lot_sqrt', 'floors', \n",
    " 'floors_square', 'waterfront', 'view', 'condition', \n",
    " 'grade', 'sqft_above', 'sqft_basement', 'yr_built', \n",
    " 'yr_renovated']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
